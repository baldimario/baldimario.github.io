---
{
  "title": "The Baron Project: Bidirectional Audio Router Over Networks",
  "description": "Multithreaded Asterisk Audiosocket Server for VOIP ChatBots",
  "image": "https://github.com/baldimario/baron/blob/main/baron.png?raw=true",
  "datetime": "2025/05/18 22:20",
  "author": "Mario Baldi"
}
---

# I Don’t Just Code. I Build What AI Can’t Replace.

*June 17, 2025*  
**Tags**: personal-branding, entrepreneurship, open-source, voip, ai, build-in-public  

---

## 🧠 From Developer to Weapon of Execution

There’s a gap in today’s software world.  
Not between junior and senior.  
Between those who follow blueprints — and those who **build the blueprint**.

I'm not chasing likes or hype.  
I'm building **real software**, solving real problems, and sharing everything I learn, every step of the way.  

> This isn’t about virality.  
> This is about visibility for the kind of thinking that makes companies say:  
> *"We need this person."*

My goal?  
To show what code looks like when it's shaped by:
- Business intuition  
- Product ownership  
- Critical thinking where AI falls short  
- A love for building tools that **do one thing well**

This is the beginning of my **build-in-public journey**, and I’m starting it with something close to my roots: **low-level audio, real-time logic, and open-source infrastructure**.

---

## 🛠️ Introducing BARON: Bidirectional Audio Router Over Networks

> **BARON** is a fast, multithreaded Asterisk audiosocket server  
> that lets LLMs **listen and speak** on real VOIP calls.

### 🧬 What It Is

BARON is a multithreaded C server that implements the Asterisk **audiosocket protocol**.  
It receives live VOIP audio streams, decodes them, detects silence, and passes the audio through a speech-to-text system.  
It then sends the recognized text to a **stateless HTTP webhook**, receives the response, generates audio using a text-to-speech engine, and sends it back to the caller.

Fully automated. Fully programmable. Fully open.

---

## ⚙️ Features

- 🧵 **Multithreaded server** – handles multiple audio streams in parallel  
- 🔊 **Ulaw/Alaw decoding → PCM 16** conversion  
- 🧘 **Audio buffering until silence is detected**  
- 🧠 **Integrates with open-source STT & TTS**:
  - [Vosk](https://alphacephei.com/vosk/) for multilingual offline speech-to-text  
  - [Kokoro](https://github.com/YourOrg/Kokoro) for open text-to-speech  
- 🌐 **Webhook-based brain** – stateless and language-agnostic  
- 🧩 Plug into any:
  - Serverless function (AWS Lambda, etc.)  
  - No-code flow (e.g. n8n, Make)  
  - Web backend in Python, Go, Rust, Node, etc.

---

## 🧭 Why I Built It

Because most AI voice systems are either:
- Cloud-locked black boxes  
- Over-engineered and under-performing  
- Or too abstracted to give you control  

I wanted something that’s:
- 🔓 Open source  
- 🔌 Composable  
- 🧼 Minimal  
- 💬 Actually usable with LLMs in real-time

---

## 📦 Use Cases

- 📞 First-level customer assistance via phone (e-commerce, support)
- 📅 Phone-based calendar slot booking  
- 🧠 LLM agents that **talk and listen** through real phone lines  
- 🔄 Any system that requires realtime, audio-triggered automation

---

## 📂 Repository

The full source is public and MIT-licensed:  
👉 [https://github.com/baldimario/baron](https://github.com/baldimario/baron)

---

## 💬 What’s Next

I’m sharing everything I build:  
- Code  
- Architecture decisions  
- Design trade-offs  
- CLI demos  
- Wins & failures

This is just the beginning.

Follow me on [GitHub](https://github.com/baldimario) and [LinkedIn](https://www.linkedin.com/in/baldimario/) if you want to build beyond the hype.

---
